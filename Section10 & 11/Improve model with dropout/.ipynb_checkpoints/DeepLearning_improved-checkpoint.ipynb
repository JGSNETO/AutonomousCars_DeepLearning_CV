{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Dropout is a regularization technique used in machine learning, specifically in training neural networks, to prevent overfitting. \n",
    "Overfitting occurs when a model performs very well on the training data but poorly on unseen test data because it has \"memorized\" the training examples rather than learning general patterns.\n",
    "\n",
    "How Dropout Works:\n",
    "During the training process, dropout randomly \"drops\" (sets to zero) a proportion of the neurons in the network, which means these neurons do not contribute to forward or backward propagation in that particular training step. \n",
    "The process is repeated for each batch during training, and the neurons that are dropped vary randomly with each batch.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from sklearn.datasets import make_classification\n",
    "from pylab import *\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Drouput\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_features=2, n_classes=4, n_samples=1000, n_redundant=0, n_informative=2, random_state=47, n_clusters_per_class=1, scale = 0.25)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(X[:,0], X[:,1], c=y.astype(np.float))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = keras.utils.to_categorical(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(16, activation='relu', input_shape=X_train.shape[1:]))\n",
    "model.add(Dense(8, activation = 'relu'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model.compile(loww='categorical_crossentropy',\n",
    "              optimier = 'adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size = 100,\n",
    "                    epochs = 100, \n",
    "                    verbose =2,\n",
    "                    validation_data = (X_test, y_test))\n",
    "\n",
    "scores= model.evaluate(X_test, y_test, verbose = 1)\n",
    "print('Test loss: ', scores[0])\n",
    "print('Test accuracy: ', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the behaviour with dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16, activation = 'relu', input_shape=X_train.shape[1:]))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size = 100,\n",
    "                    epochs = 100,\n",
    "                    verbose=2,\n",
    "                    validatin_data = (X_test, y_test))\n",
    "\n",
    "scores = model.evaluate(X_test, y_test, verbose = 1)\n",
    "print('Test loss: ', scores[0])\n",
    "print('Test accuracy: ', scores[1])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
