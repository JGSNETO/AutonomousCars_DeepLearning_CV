{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ea2e7e0-c644-4096-9097-67c4c6f4cdad",
   "metadata": {},
   "source": [
    "# Image Features and their importance for object detection\n",
    "\n",
    "## Introduction\n",
    "\n",
    "- Image features are important areas an image that are unique to a specific image.\n",
    "- A feature is a piece of information in the image such as points, edges or objects that is different/unique.\n",
    "- A feature may be a color or a detected edge.\n",
    "- A good feature has to be repeatable: If feature can be detected in two or more different images of the same scene.\n",
    "\n",
    "## Why are features important ?\n",
    "\n",
    "- Image Features are critical in machine learning and self-driving cars because they can be used to analyze, describe and match images.\n",
    "- Features can be used to train a classifier to detet objects such as pedestrians and cars. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e7289c-397a-42bd-8ac1-ed68b18935d3",
   "metadata": {},
   "source": [
    "# Template Matching\n",
    "\n",
    "- Our goal is to find objects(truck) in this image using template matching.\n",
    "- OpenCV has functions to perform this easily: cv2.matchTemplate(), cv2.minMaxLoc()\n",
    "- cv2.matchTemplate() simply slides the template image over the input image and compares the template and patch of input image under the template image.\n",
    "- The functions returns a grayscale image, where each pixel denotes how much does the neighbourhood of that piel match with template.\n",
    "- If input image is of size (WxH) and template image is of size (wxh), output image will have a size of( W-w+1, H-h+1).\n",
    "- Once you got the result, cv2.minMaxLoc() function is used to find where is the maximum/minimum value. Take it as the top-left corner of rectangle and take(w,h) as width and height of the rectangle. That rectangle is the region of template.\n",
    "- Template has to be in the same orientation as in the original image\n",
    "- Image size and scale is a challenge.\n",
    "- Driving conditions such as weather, brightness and contrast.\n",
    "- Perspective will challenge the technique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e7f0fb-eb0e-4219-b16d-58a76beb8d67",
   "metadata": {},
   "source": [
    "# Corners and Edges as Features \n",
    "- Edges are identified when change in intensity is noticed in one direction.\n",
    "- Corners are identified when shifiting a windows in any direction over the point gives a large change in intensity in all directions.\n",
    "## Corners and Edges as Features\n",
    "- Corners are regions in the image with large variations in intensity in all the directions.\n",
    "- Harris corner detection finds the difference in intensity for a displacements of (u,v) in all directions.\n",
    "- OpenCV has the function cv2.cornerHarris(img, block size, ksieze, k)\n",
    "1. img: Input image, it should be grayscale and float32 type.\n",
    "2. blockSize: It is the size of neighbourhood considered for corner detection\n",
    "3. ksize: Aperture parameter of Sobel derivative used\n",
    "4. k: Harris detector free parameter in the equation(set to 0.1)\n",
    "## Limitations\n",
    "- Detection corners as features in images can work well even of the image is:\n",
    "1. rotated, translated and experienced changes in brightness\n",
    "2. i.e: Even if the image is rotated, we can still find the same corners\n",
    "- The technique is challenged if the image is enlarged(scaling issues)\n",
    "1. A corner may not be a corner if the image is scaled\n",
    "2. A corner in a small image would result in multiple corners in a zoomed-in larger image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8175bd53-abbf-4f71-8263-d140f3ae7fda",
   "metadata": {},
   "source": [
    "# Image schaling: Pyramiding up/down\n",
    "\n",
    "- Image pyramiding refers to resizing the image by enlarging or shriking.\n",
    "- Pyramiding is important in object detection since it allows us to search for the object at various scales.\n",
    "- An image pyramid is a collection of images - all arising from a single original image - that are successively down sampled until some desired stopping point is reached.\n",
    "- By doing so, a MxN image becomes M/2xN/2 image. So area reduces to one-forth of roginal area.\n",
    "- Pyramiding is used for template matching by finding an object at different scales.\n",
    "- Gaussian pyramiding is one of the common types of image pyrimiding and is used to down sample images.\n",
    "- Filtering the image, then subsample enhances the image quality(smoothness)\n",
    "- Gaussian pyramids steps:\n",
    "1. Convolve the image with a gaussian kernel\n",
    "2. Remove every even-numbered row and column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1fe3ee-82df-4fd1-a7fa-d1ff82aa27fd",
   "metadata": {},
   "source": [
    "# Histogram of colors\n",
    "- We can use the color histogram for feature detection, openCV has a histogram function as follows:\n",
    "1. cv2.calcHist([image], [channels], mask, [histSize], [ranges])\n",
    "- Images: source image.\n",
    "- Channels: Histogram index of channels, i.e: [0], [1] or [2] for blue, green or red channel respectively.\n",
    "- Mask: put \"None\" for the entire image.\n",
    "- histSize: bin count, put [256] for full scale.\n",
    "- ranges: put [0,256]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7261a6ee-829e-4320-b324-3bfdc10474c3",
   "metadata": {},
   "source": [
    "# Feature Extraction - SIFT, SURF, FAST and ORB\n",
    "\n",
    "- FAST(Features from Accelerated Segment Test) algorithm was proposed by Edward Rosten and Tom Drummond in their paper \"Machine Learning for High-Speed corner detection\"\n",
    "- STEPS:\n",
    "1. Select a pixel p in the image which is to be identified as an interest point\n",
    "2. Gets its intensity Ip\n",
    "3. Select appropriate threshold value t\n",
    "4. Consider a circle of 16 pixels around the pixel under test\n",
    "5. Pixel p is a corner if there exists a set of contiguous pixels in the circle which are all brighter than ip + t, or all darken than ip - t\n",
    "6. A high-speed test that four pixels at 1, 9, 5 and 13. If p is a corner, then at least three of these must all be brighter than ip + t or darker than ip - t. If neither of these is the case, then p cannot be a corner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3556040-5578-4d80-bf56-f0c9ccbbb1c4",
   "metadata": {},
   "source": [
    "# Histogram of Oriented Gradients (HOG)\n",
    "\n",
    "## Intuition\n",
    "\n",
    "- For function f(x,y), the gradient is the vector(fx, fy)\n",
    "- An image is a discrete function of (x,y) so image gradient can be calculated as well\n",
    "- At each pixel, image gradient horizontal (x-direction) and vertical (y-direction) are calculated\n",
    "- These vectors have a direction atan(fy/fx) and a magnitude ( raiz((fx^2 + fy^2)))\n",
    "- Gradient values are mapped to 0-255. Pixels with large negative change will be black, pixels with large positive change will be white, and pixels with little or no change will be gray\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e410ac-f4e7-4221-bef3-fd04482f6943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2de94cf-85fe-4294-823a-9d2533c383fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
