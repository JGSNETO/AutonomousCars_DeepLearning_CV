{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ea2e7e0-c644-4096-9097-67c4c6f4cdad",
   "metadata": {},
   "source": [
    "# Image Features and their importance for object detection\n",
    "\n",
    "## Introduction\n",
    "\n",
    "- Image features are important areas an image that are unique to a specific image.\n",
    "- A feature is a piece of information in the image such as points, edges or objects that is different/unique.\n",
    "- A feature may be a color or a detected edge.\n",
    "- A good feature has to be repeatable: If feature can be detected in two or more different images of the same scene.\n",
    "\n",
    "## Why are features important ?\n",
    "\n",
    "- Image Features are critical in machine learning and self-driving cars because they can be used to analyze, describe and match images.\n",
    "- Features can be used to train a classifier to detet objects such as pedestrians and cars. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e7289c-397a-42bd-8ac1-ed68b18935d3",
   "metadata": {},
   "source": [
    "# Template Matching\n",
    "\n",
    "- Our goal is to find objects(truck) in this image using template matching.\n",
    "- OpenCV has functions to perform this easily: cv2.matchTemplate(), cv2.minMaxLoc()\n",
    "- cv2.matchTemplate() simply slides the template image over the input image and compares the template and patch of input image under the template image.\n",
    "- The functions returns a grayscale image, where each pixel denotes how much does the neighbourhood of that piel match with template.\n",
    "- If input image is of size (WxH) and template image is of size (wxh), output image will have a size of( W-w+1, H-h+1).\n",
    "- Once you got the result, cv2.minMaxLoc() function is used to find where is the maximum/minimum value. Take it as the top-left corner of rectangle and take(w,h) as width and height of the rectangle. That rectangle is the region of template.\n",
    "- Template has to be in the same orientation as in the original image\n",
    "- Image size and scale is a challenge.\n",
    "- Driving conditions such as weather, brightness and contrast.\n",
    "- Perspective will challenge the technique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e7f0fb-eb0e-4219-b16d-58a76beb8d67",
   "metadata": {},
   "source": [
    "# Corners and Edges as Features \n",
    "- Edges are identified when change in intensity is noticed in one direction.\n",
    "- Corners are identified when shifiting a windows in any direction over the point gives a large change in intensity in all directions.\n",
    "## Corners and Edges as Features\n",
    "- Corners are regions in the image with large variations in intensity in all the directions.\n",
    "- Harris corner detection finds the difference in intensity for a displacements of (u,v) in all directions.\n",
    "- OpenCV has the function cv2.cornerHarris(img, block size, ksieze, k)\n",
    "1. img: Input image, it should be grayscale and float32 type.\n",
    "2. blockSize: It is the size of neighbourhood considered for corner detection\n",
    "3. ksize: Aperture parameter of Sobel derivative used\n",
    "4. k: Harris detector free parameter in the equation(set to 0.1)\n",
    "## Limitations\n",
    "- Detection corners as features in images can work well even of the image is:\n",
    "1. rotated, translated and experienced changes in brightness\n",
    "2. i.e: Even if the image is rotated, we can still find the same corners\n",
    "- The technique is challenged if the image is enlarged(scaling issues)\n",
    "1. A corner may not "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
